{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78534dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import login\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176985a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_data import import_parade, import_bbc, import_textbook\n",
    "from prepare_data import prep_parade, prep_bbc, prep_textbook\n",
    "from benchmark import aggregate_similarity, cluster_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73970c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb43ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentences):\n",
    "    return embedding_model.encode(\n",
    "        sentences,\n",
    "        progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(sentences, sentence_embeddings, threshold_multiplier = 1):\n",
    "  distances = cosine_distances(sentence_embeddings)\n",
    "  distance_threshold = np.mean(distances) * threshold_multiplier\n",
    "\n",
    "  clustering_model = AgglomerativeClustering(\n",
    "      n_clusters = None,\n",
    "      metric = \"precomputed\",\n",
    "      distance_threshold = distance_threshold,\n",
    "      linkage = \"complete\"\n",
    "  )\n",
    "\n",
    "  clustering_model.fit(distances)\n",
    "\n",
    "  labels = clustering_model.labels_\n",
    "\n",
    "  number_of_lables = 1 + max(labels)\n",
    "\n",
    "  clusters = [[] for _ in range(number_of_lables)]\n",
    "\n",
    "  for index, label in enumerate(labels):\n",
    "    clusters[label].extend(sentences[index].strip())\n",
    "\n",
    "  return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64367f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_chunking(sentences, threshold_multiplier = 1):\n",
    "  chunks = []\n",
    "  current_sentence_chunk = []\n",
    "  added_indexes = set()\n",
    "\n",
    "  sentence_embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "  average_similarity = np.mean(cosine_similarity(sentence_embeddings))\n",
    "  similarity_threshold = average_similarity * threshold_multiplier\n",
    "\n",
    "  for j in range(len(sentences)):\n",
    "    for i in range(len(sentences)):\n",
    "      if not current_sentence_chunk and i not in added_indexes:\n",
    "        current_sentence_chunk.append(sentences[i])\n",
    "        added_indexes.add(i)\n",
    "      elif i not in added_indexes:\n",
    "        chunk_embeddings = embedding_model.encode(current_sentence_chunk)\n",
    "\n",
    "        avg_chunk_embeddings = np.mean(chunk_embeddings, axis = 0)\n",
    "\n",
    "        similarity = cosine_similarity([avg_chunk_embeddings], [sentence_embeddings[i]])\n",
    "\n",
    "        if similarity > similarity_threshold:\n",
    "          current_sentence_chunk.append(sentences[i].strip())\n",
    "          added_indexes.add(i)\n",
    "\n",
    "    if current_sentence_chunk:\n",
    "      chunks.append(current_sentence_chunk)\n",
    "      current_sentence_chunk = []\n",
    "\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c25f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_chunking_sliding_window(sentences, threshold_multiplier = 1, window_size = 15):\n",
    "  chunks = []\n",
    "  current_chunk_sentences = []\n",
    "\n",
    "  sentence_embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "  for i in range(len(sentences)):\n",
    "    if not current_chunk_sentences:\n",
    "        current_chunk_sentences.append(sentences[i])\n",
    "    else:\n",
    "        current_chunk_embeddings = embedding_model.encode(current_chunk_sentences)\n",
    "\n",
    "        avg_chunk_embedding = np.mean(current_chunk_embeddings, axis = 0)\n",
    "\n",
    "        similarity = cosine_similarity([sentence_embeddings[i]],[avg_chunk_embedding])\n",
    "        similarity_threshold = similarity * threshold_multiplier\n",
    "        if similarity >= similarity_threshold:\n",
    "            current_chunk_sentences.append(sentences[i])\n",
    "        else:\n",
    "            chunks.append(current_chunk_sentences)\n",
    "            current_chunk_sentences = []\n",
    "\n",
    "    if len(current_chunk_sentences) >= window_size and i < len(sentences) - 1:\n",
    "        chunks.append(current_chunk_sentences)\n",
    "\n",
    "    if current_chunk_sentences:\n",
    "        chunks.append(current_chunk_sentences)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe029399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individualize_sentences(data) -> list:\n",
    "    sentence_data = []\n",
    "    if type(data) is list:\n",
    "      for paragraphs in data:\n",
    "          doc = nlp(paragraphs)\n",
    "          for sent in doc.sents:\n",
    "            sentence_data.append(sent.text)\n",
    "      return sentence_data\n",
    "    elif type(data) is str:\n",
    "      sentence_data = []\n",
    "      doc = nlp(data)\n",
    "      for sent in doc.sents:\n",
    "        sentence_data.append(sent.text)\n",
    "      return sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_parade()\n",
    "parade = prep_parade()\n",
    "parade_sentences = individualize_sentences(parade)\n",
    "parade_embeddings = get_sentence_embeddings(parade_sentences)\n",
    "parade_clusters = clustering(parade_sentences, parade_embeddings, 1.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_semantics = []\n",
    "for chunk in enumerate(parade_clusters):\n",
    "    parade_semantics.extend(semantic_chunking(chunk, 1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in parade]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in parade_semantics]))\n",
    "parade_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in parade], \n",
    "    parade_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Parade\")\n",
    "print(f\"Aggregate Similarity: {parade_aggregate_score}\")\n",
    "print(f\"ARI: {parade_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {parade_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {parade_cluster_scores[\"v_measure\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb290c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_bbc(HF_TOKEN)\n",
    "bbc = prep_bbc()\n",
    "bbc_sentences = individualize_sentences(bbc)\n",
    "bbc_embeddings = get_sentence_embeddings(bbc_sentences)\n",
    "bbc_clusters = clustering(bbc_sentences, bbc_embeddings, 1.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85904d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_semantics = []\n",
    "for chunk in enumerate(bbc_clusters):\n",
    "    bbc_semantics.extend(semantic_chunking(chunk, 1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in bbc]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in bbc_semantics]))\n",
    "bbc_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in bbc], \n",
    "    bbc_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1752e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BBC\")\n",
    "print(f\"Aggregate Similarity: {bbc_aggregate_score}\")\n",
    "print(f\"ARI: {bbc_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {bbc_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {bbc_cluster_scores[\"v_measure\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import_textbook(HF_TOKEN)\n",
    "textbook = prep_textbook()\n",
    "textbook_sentences = individualize_sentences(textbook)\n",
    "textbook_embeddings = get_sentence_embeddings(textbook_sentences)\n",
    "textbook_clusters = clustering(textbook_sentences, textbook_embeddings, 1.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be103dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_semantics = []\n",
    "for chunk in enumerate(textbook_clusters):\n",
    "    textbook_semantics.extend(semantic_chunking(chunk, 1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in textbook]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in textbook_semantics]))\n",
    "textbook_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in textbook], \n",
    "    textbook_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2367857",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Textbook\")\n",
    "print(f\"Aggregate Similarity: {textbook_aggregate_score}\")\n",
    "print(f\"ARI: {bbc_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {bbc_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {bbc_cluster_scores[\"v_measure\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_parade_semantics = []\n",
    "for chunk in enumerate(parade_clusters):\n",
    "    parade_semantics.extend(semantic_chunking_sliding_window(chunk, 1.3))\n",
    "\n",
    "sliding_bbc_semantics = []\n",
    "for chunk in enumerate(bbc_clusters):\n",
    "    bbc_semantics.extend(semantic_chunking_sliding_window(chunk, 1.3))\n",
    "\n",
    "sliding_textbook_semantics = []\n",
    "for chunk in enumerate(textbook_clusters):\n",
    "    textbook_semantics.extend(semantic_chunking_sliding_window(chunk, 1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483caedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_parade_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in parade]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in parade_semantics]))\n",
    "sliding_parade_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in parade], \n",
    "    parade_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)\n",
    "\n",
    "sliding_bbc_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in bbc]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in bbc_semantics]))\n",
    "sliding_bbc_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in bbc], \n",
    "    bbc_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)\n",
    "\n",
    "sliding_textbook_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in textbook]), \n",
    "    get_sentence_embeddings([\" \".join(chunks) for chunks in textbook_semantics]))\n",
    "sliding_textbook_cluster_scores = cluster_similarity(\n",
    "    [individualize_sentences(chunks) for chunks in textbook], \n",
    "    textbook_semantics, \n",
    "    nmi_method=\"geometric\", \n",
    "    v_beta = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Parade\")\n",
    "print(f\"Aggregate Similarity: {sliding_parade_aggregate_score}\")\n",
    "print(f\"ARI: {sliding_parade_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {sliding_parade_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {sliding_parade_cluster_scores[\"v_measure\"]}\")\n",
    "\n",
    "print(f\"BBC\")\n",
    "print(f\"Aggregate Similarity: {sliding_bbc_aggregate_score}\")\n",
    "print(f\"ARI: {sliding_bbc_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {sliding_bbc_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {sliding_bbc_cluster_scores[\"v_measure\"]}\")\n",
    "\n",
    "print(f\"Textbook\")\n",
    "print(f\"Aggregate Similarity: {sliding_textbook_aggregate_score}\")\n",
    "print(f\"ARI: {sliding_bbc_cluster_scores[\"ari\"]}\")\n",
    "print(f\"NMI: {sliding_bbc_cluster_scores[\"nmi\"]}\")\n",
    "print(f\"V_Measure: {sliding_bbc_cluster_scores[\"v_measure\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
