{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78534dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import login\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176985a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_data import import_parade, import_bbc, import_textbook\n",
    "from prepare_data import prep_parade, prep_bbc, prep_textbook\n",
    "from benchmark import aggregate_similarity, cluster_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_parade()\n",
    "import_bbc(HF_TOKEN)\n",
    "import_textbook(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade = prep_parade()\n",
    "bbc = prep_bbc()\n",
    "textbook = prep_textbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73970c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb43ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentences):\n",
    "    return embedding_model.encode(\n",
    "        sentences,\n",
    "        progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(sentences, sentence_embeddings, threshold_multiplier = 0.8):\n",
    "  distances = cosine_distances(sentence_embeddings)\n",
    "  distance_threshold = np.mean(distances) * threshold_multiplier\n",
    "\n",
    "  clustering_model = AgglomerativeClustering(\n",
    "      n_clusters = None,\n",
    "      metric = \"precomputed\",\n",
    "      distance_threshold = distance_threshold,\n",
    "      linkage = \"complete\"\n",
    "  )\n",
    "\n",
    "  clustering_model.fit(distances)\n",
    "\n",
    "  labels = clustering_model.labels_\n",
    "\n",
    "  number_of_lables = 1 + max(labels)\n",
    "\n",
    "  clusters = [[] for _ in range(number_of_lables)]\n",
    "\n",
    "  for index, label in enumerate(labels):\n",
    "    clusters[label].append(sentences[index].strip())\n",
    "\n",
    "  return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64367f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_chunking(sentences, threshold_multiplier = 1.3):\n",
    "  chunks = []\n",
    "  current_sentence_chunk = []\n",
    "  added_indexes = set()\n",
    "\n",
    "  sentence_embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "  average_similarity = np.mean(cosine_similarity(sentence_embeddings))\n",
    "  similarity_threshold = average_similarity * threshold_multiplier\n",
    "\n",
    "  for j in range(len(sentences)):\n",
    "    for i in range(len(sentences)):\n",
    "      if not current_sentence_chunk and i not in added_indexes:\n",
    "        current_sentence_chunk.append(sentences[i])\n",
    "        added_indexes.add(i)\n",
    "      elif i not in added_indexes:\n",
    "        chunk_embeddings = embedding_model.encode(current_sentence_chunk)\n",
    "\n",
    "        avg_chunk_embeddings = np.mean(chunk_embeddings, axis = 0)\n",
    "\n",
    "        similarity = cosine_similarity([avg_chunk_embeddings], [sentence_embeddings[i]])\n",
    "\n",
    "        if similarity > similarity_threshold:\n",
    "          current_sentence_chunk.append(sentences[i].strip())\n",
    "          added_indexes.add(i)\n",
    "\n",
    "    if current_sentence_chunk:\n",
    "      chunks.append(current_sentence_chunk)\n",
    "      current_sentence_chunk = []\n",
    "\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe029399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individualize_sentences(data) -> list:\n",
    "    sentence_data = []\n",
    "    for paragraphs in data:\n",
    "        doc = nlp(paragraphs)\n",
    "        sentence_data.extend([sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235239af",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_sentences = individualize_sentences(parade)\n",
    "bbc_sentences = individualize_sentences(bbc)\n",
    "textbook_sentences = individualize_sentences(textbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee50339",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_embeddings = get_sentence_embeddings(parade_sentences)\n",
    "bbc_embeddings = get_sentence_embeddings(bbc_sentences)\n",
    "textbook_embeddings = get_sentence_embeddings(textbook_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b308911",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_clusters = clustering(parade_sentences, parade_embeddings)\n",
    "bbc_clusters = clustering(bbc_sentences, bbc_embeddings)\n",
    "textbook_clusters = clustering(textbook_sentences, textbook_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be103dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_semantics = semantic_chunking(parade_clusters)\n",
    "bbc_semantics = semantic_chunking(bbc_clusters)\n",
    "textbook_semantics = semantic_chunking(textbook_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "parade_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in parade]), \n",
    "    get_sentence_embeddings([chunks for chunks in parade_semantics]))\n",
    "parade_cluster_scores = cluster_similarity(parade, parade_semantics, nmi_method=\"geometric\", v_beta = 0.85)\n",
    "\n",
    "bbc_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in bbc]), \n",
    "    get_sentence_embeddings([chunks for chunks in bbc_semantics]))\n",
    "bbc_cluster_scores = cluster_similarity(bbc, bbc_semantics, nmi_method=\"geometric\", v_beta = 0.85)\n",
    "\n",
    "textbook_aggregate_score = aggregate_similarity(\n",
    "    get_sentence_embeddings([chunks for chunks in textbook]), \n",
    "    get_sentence_embeddings([chunks for chunks in textbook_semantics]))\n",
    "textbook_cluster_scores = cluster_similarity(textbook, textbook_semantics, nmi_method=\"geometric\", v_beta = 0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
